{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement IP Data Downloader\n",
    "__authors__: ufukbombar@gmail.com\n",
    "\n",
    "__date__: 2024-11-24\n",
    "\n",
    "__goal__: This notebook downloads the ip routing information into binary files given the measurement id. The format is given.\n",
    "\n",
    "__input__:\n",
    " - The measurement table as .feather file from `table_to_measurement_converter`.\n",
    " - The measurement_uuid given by the user.\n",
    "\n",
    " __output__:\n",
    "  - The binary data for each agent under the data dir.\n",
    "\n",
    "__notes__:\n",
    "The only required fields for finding out the routing is ['probe_dst_prefix', 'reply_src_prefix']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "%pip install pandas requests python-dotenv httpx aiofiles dataclasses tqdm pyarrow\n",
    "\n",
    "# External imports\n",
    "import pandas as pd \n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import asyncio\n",
    "import os\n",
    "import ipaddress\n",
    "\n",
    "# Internal imports\n",
    "from config import config, Config\n",
    "import common\n",
    "import file as ff\n",
    "import objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the output of table_downloader\n",
    "input_tables_name = \"../data/measurements/measurement-2024-11-18 22:44:16.feather\"\n",
    "selected_measurement_uuid = \"007046a9_518e_46cb_8e70_e598b8bce831\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_tables_df = pd.read_feather(input_tables_name)\n",
    "measurement_tables_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_measurements_df = measurement_tables_df[\n",
    "    (measurement_tables_df['cleaned'] == True) & \n",
    "    (measurement_tables_df['measurement_uuid'] == selected_measurement_uuid) & \n",
    "    (measurement_tables_df['type'] == 'results')\n",
    "]\n",
    "selected_measurements_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the df to list[dataclass: Measurement]\n",
    "selected_measurements_list = [objects.Measurement(**row) for _, row in selected_measurements_df.iterrows()]\n",
    "print(f\"There are {len(selected_measurements_list)} table(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_number_of_row(m: objects.Measurement): \n",
    "    q_size = f\"select count(*) from {m.table_name}\"\n",
    "    cfg = Config()\n",
    "    cfg.response_format = \"CSV\"\n",
    "    raw_response = await common.quick_query(cfg, q_size)\n",
    "    return int(raw_response.decode())\n",
    "\n",
    "async def get_results_table_optimized(m: objects.Measurement, num_rows: int, limit: int=1):\n",
    "    # Define the packing/compression function\n",
    "    def from_csv_to_int(binary_data: bytes):\n",
    "        a, b = binary_data[:-1].split(b',')\n",
    "        a, b = a[1:-1], b[1:-1]\n",
    "        a, b = a.decode(), b.decode()\n",
    "        a, b = ipaddress.IPv6Address(a).ipv4_mapped, ipaddress.IPv6Address(b).ipv4_mapped\n",
    "\n",
    "        if a == None or b == None:\n",
    "            return b'', False\n",
    "\n",
    "        # remove the last byte since it is a prefix. The reouting information is represented with \n",
    "        # 3 + 3 = 6 bytes.\n",
    "        return a.packed[:-1] + b.packed[:-1], True\n",
    "\n",
    "    # Get the default config\n",
    "    cfg = Config()\n",
    "    cfg.response_format = \"CSV\"\n",
    "\n",
    "    # Set the quert string\n",
    "    q = f\"select probe_dst_prefix, reply_src_prefix from {m.table_name}{'' if limit == 0 else ' limit ' + str(limit)}\"\n",
    "    q_size = f\"select count(*) from {m.table_name}\"\n",
    "\n",
    "    # Determine the name of the binary data\n",
    "    filepath = f\"../data/ip_data/{m.measurement_uuid}-{ff.get_timestr()}/{m.table_name}.bin\"\n",
    "    num_pairs_written = 0\n",
    "    num_pairs_expected = num_rows\n",
    "    \n",
    "    try:\n",
    "        with ff.BinaryFile(filepath) as bf:\n",
    "            async for row in tqdm(common.run_query_iter_lines(cfg, q), desc=\"Downloading to binary data\"):\n",
    "                row: bytes\n",
    "                b, ok = from_csv_to_int(row)\n",
    "                if not ok: continue\n",
    "                num_pairs_written += 1\n",
    "\n",
    "                if num_pairs_written % 1000:\n",
    "                    print(f\"from {m.table_name} done {}\")\n",
    "                bf.write(b)\n",
    "    except Exception:\n",
    "        print(f\"Exception on {m.table_name}, exitting\")\n",
    "        return False, num_pairs_expected, num_pairs_written\n",
    "\n",
    "    return True, num_pairs_expected, num_pairs_written\n",
    "\n",
    "async def get_results_table_optimized_from_list(m_list: list[objects.Measurement], limit: int=1):\n",
    "    num_rows = await asyncio.gather(*[get_number_of_row(m) for m in m_list])\n",
    "    print(f\"Will download total of {sum(num_rows)} row(s)\")\n",
    "\n",
    "    return await asyncio.gather(*[get_results_table_optimized(m, num_rows, limit=limit) for m, num_rows in zip(m_list, num_rows)])\n",
    "\n",
    "ok_expected_writted_list = await get_results_table_optimized_from_list(selected_measurements_list, limit=10000)\n",
    "# await get_results_table_optimized(selected_measurements_list[0], limit=1)\n",
    "\n",
    "for m, (ok, expected, written) in zip(selected_measurements_list, ok_expected_writted_list):\n",
    "    print(f\"For agent {m.agent_uuid} {written}/{expected} pairs are saved with {'success' if ok else 'error'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for ip conversion -> IT WORKS\n",
    "def from_bin_to_ipv4(binary_data: bytes):\n",
    "    a, b = binary_data[:3] + b'\\00', binary_data[3:] + b'\\00'\n",
    "    return ipaddress.ip_address(a), ipaddress.ip_address(b)\n",
    "\n",
    "from_bin_to_ipv4(b'\\x01\\x00\\xd5\\xcb\\xbe\\xfa') # expected (\"::ffff:1.0.213.0\",\"::ffff:203.190.250.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "async def nested_task(task_id, total_steps):\n",
    "    # Create a nested progress bar for each task\n",
    "    for i in tqdm(range(total_steps), desc=f\"Subtask {task_id}\", leave=False, ncols=100):\n",
    "        await asyncio.sleep(0.1)  # Simulate async work\n",
    "\n",
    "async def main_task(task_id, total_subtasks, subtask_steps):\n",
    "    # Create a progress bar for the main task\n",
    "    for i in tqdm(range(total_subtasks), desc=f\"Main Task {task_id}\", ncols=100):\n",
    "        # Simulate async work for the main task\n",
    "        await asyncio.sleep(0.2)\n",
    "        \n",
    "        # Call the nested task and await it\n",
    "        await nested_task(i, subtask_steps)\n",
    "\n",
    "async def main():\n",
    "    total_tasks = 3  # Total number of main tasks\n",
    "    total_subtasks = 5  # Subtasks per main task\n",
    "    subtask_steps = 4  # Steps per nested subtask\n",
    "\n",
    "    tasks = []\n",
    "    for i in range(total_tasks):\n",
    "        tasks.append(main_task(i, total_subtasks, subtask_steps))\n",
    "\n",
    "    # Run all tasks concurrently\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the main async function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
